---
title: "Assignment 3 - Forecast average monthly bus ridership for Gotham city - Nicholas Petr"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

### Import Required Packages

```{r}
# Import required packages
library(tseries)
library(forecast)
library(xts)
```

### Load Data 

```{r}
df <- read.csv("C:/Users/Nick's Laptop/Desktop/Time Series Analysis/week3/average-monthly-ridership.csv")
```
## Questions
### 1. Use xts package to divide the data into train (ending and including Dec 2018) and test (Jan - Jun 2019).


```{r}
rides = df$average.monthly.bus.ridership.in.100
dfTS = ts(rides, start = 2010, frequency = 12) # convert df to time series 

dfTS = as.xts(dfTS) # convert time series to xts 
train = dfTS['/2018'] # the beginning of the data through Dec 2018
test = dfTS['2019/']  # Jan - Jun 2019 
```

### 2. EDA of train data - qualitative analysis and indicate for each of the following if you think TS is stationary or not and why?

### 2.1 Data Plot

### Findings from Data Plot:
Looking at the plot, we can see that this TS is a random walk process. Therefore, this would indicate the data is non-stationary, as all random walk processes are non-stationary. 
```{r}
plot(train)
```

### 2.2 acf Plot

### Findings 
We again see within the acf plot that the TS is non-stationary. We conclude this because the lag dies down very slowly, which indicates non-stationarity. If the data were stationary, we would expect to see the lag die very quickly and fall within the margins indicated by the blue dotted line.
```{r}
acf(train)
```

### 3. EDA of train data - quantitative analysis - does it support the qualitative analysis?

To quantitatively analyze stationarity, we will conduct an ADF test and KPSS test. Per Lecture 1, I am making the assumption that a 95% significance level (p-value < 0.05) is enough to reject H0.

ADF Test: HO = Non-Stationary TS (Delta = 0). H1 = Stationary TS (Delta != 0)
We see that the ADF test returns a very high p-value (0.4989), indicating that the data is Non-Stationary per the null hypothesis. 

KPSS: H0 = Stationary. H1: Data is Non-Stationary
We see that the KPSS test returns a p-value less than 0.01, indicating that we can reject the null hypothesis and conclude the TS is non-stationary.
```{r}
# ADF Test on train TS
adf.test(train)
# KPSS Test on train TS
kpss.test(train)

```

### 4. Use forecast::auto.arima with no seasonality to get a baseline model 

### What is the order (p, d, q) of the model?
As you can see from the output of the auto.arima model output, we have a (p, d, q) order of (0, 1, 2). We remove seasonality from the model by converting seasonal to FALSE.

```{r}
baseArima = forecast::auto.arima(train, seasonal=FALSE)
baseArima
```

### 5. Does the d support your EDA analysis for stationarity - why?
d does support our EDA analysis for stationarity. For our auto.arima output, d = 1. Per our course materials, when drift is present, d will always equal 1. When drift is present, we have non-stationary data. 

### 6. Plot forecasts of the baseline model for 2019.
```{r}
plot(forecast(baseArima, h=12))
```

### 7. Run forecast::accuracy for the baseline model.
```{r}
forecast::accuracy(baseArima)
```

### 8. Use forecast::Arima with no seasonality and change p and/or q to try at least 2 additional models with different orders.

Model 1: p=0, q=3, d remains at 1
Model 2: p=1, q=0, d remains at 1

Note that we need to include drift given that our d value is 1. Otherwise there will be no movement in the associated plot forecast and the scoring will be negatively impacted
```{r}
# Model 1: p=0, q=3, d remains at 1
model1 = forecast::Arima(train, order = c(0,1,3), include.drift = T) 
summary(model1)

# Model 2: p=1, q=0, d remains at 1
model2 = forecast::Arima(train, order = c(1,1,0), include.drift = T) # Simple Exponential Smoothing 
summary(model2)
```

### 9. Plot forecasts of the additional models for 2019.
```{r}
# Model 1 Plot 
plot(forecast(model1, h=12))
# Model 2 Plot
plot(forecast(model2, h=12))
```

### 10. Run forecast::accuracy for the additional models

### 10.1 Which model has the best test RMSE?
Model 2 (1, 1, 0) has the best test RMSE at 39.8011.
```{r}
# Accuracy for Model 1 using the test dataset
model1_accuracy <- Arima(test, model=model1)
accuracy(model1_accuracy)

# Accuracy for Model 2 using the test dataset
model2_accuracy <- Arima(test, model=model2)
accuracy(model2_accuracy)
```

### 10.2 which model has the lowest train ACF1 (autocorrelation of errors at lag 1)?
Model 2 (1, 1, 0) has the lowest train ACF1 at -0.0058
```{r}
# Accuracy for Model 1 using the train dataset
model1_accuracy_train <- Arima(train, model=model1)
accuracy(model1_accuracy_train)

# Accuracy for Model 2 using the train dataset
model2_accuracy_train <- Arima(train, model=model2)
accuracy(model2_accuracy_train)
```