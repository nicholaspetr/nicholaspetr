{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8baa278e",
   "metadata": {},
   "source": [
    "# Medical Image Analysis, Nicholas Petr, Assignment 3, MSCA 3200091\n",
    "\n",
    "Resources: \n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "\n",
    "https://pyimagesearch.com/2018/12/03/deep-learning-and-medical-image-analysis-with-keras/\n",
    "\n",
    "https://studymachinelearning.com/keras-imagedatagenerator-with-flow_from_directory/\n",
    "\n",
    "https://ecode.dev/cnn-for-medical-imaging-using-tensorflow-2/\n",
    "\n",
    "https://developers.google.com/codelabs/tensorflow-6-largecnns#5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6c7e45",
   "metadata": {},
   "source": [
    "## Load packages and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1c9d0aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "import os\n",
    "import config\n",
    "from imutils import paths\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from keras_tuner import HyperModel\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c97bed",
   "metadata": {},
   "source": [
    "## Initialize data pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e27133de",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_input_dataset = r\"C:\\Users\\Nick's Laptop\\Desktop\\Health Analyics\\medical_image_analysis\\malaria\\cell_images\"\n",
    "base_path = r\"C:\\Users\\Nick's Laptop\\Desktop\\Health Analyics\\medical_image_analysis\\malaria\"\n",
    "\n",
    "train_path = r\"C:\\Users\\Nick's Laptop\\Desktop\\Health Analyics\\medical_image_analysis\\malaria\\training\"\n",
    "val_path = r\"C:\\Users\\Nick's Laptop\\Desktop\\Health Analyics\\medical_image_analysis\\malaria\\validation\"\n",
    "test_path = r\"C:\\Users\\Nick's Laptop\\Desktop\\Health Analyics\\medical_image_analysis\\malaria\\testing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505745cd",
   "metadata": {},
   "source": [
    "## Split into train/test datasets, with 10% of training dataset going to validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f143ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = list(paths.list_images(orig_input_dataset))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "train_split = 0.8\n",
    "val_split = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45436530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19842 2204 5512\n"
     ]
    }
   ],
   "source": [
    "i = int(len(imagePaths) * train_split)\n",
    "trainPaths = imagePaths[:i]\n",
    "testPaths = imagePaths[i:]\n",
    "\n",
    "i = int(len(trainPaths) * val_split)\n",
    "valPaths = trainPaths[:i]\n",
    "trainPaths = trainPaths[i:]\n",
    "\n",
    "print(len(trainPaths),len(valPaths),len(testPaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7970b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building 'training' split\n",
      "[INFO] 'creating C:\\Users\\Nick's Laptop\\Desktop\\Health Analyics\\medical_image_analysis\\malaria\\training\\Parasitized' directory\n",
      "[INFO] 'creating C:\\Users\\Nick's Laptop\\Desktop\\Health Analyics\\medical_image_analysis\\malaria\\training\\Uninfected' directory\n",
      "[INFO] building 'validation' split\n",
      "[INFO] 'creating C:\\Users\\Nick's Laptop\\Desktop\\Health Analyics\\medical_image_analysis\\malaria\\validation\\Parasitized' directory\n",
      "[INFO] 'creating C:\\Users\\Nick's Laptop\\Desktop\\Health Analyics\\medical_image_analysis\\malaria\\validation\\Uninfected' directory\n",
      "[INFO] building 'testing' split\n",
      "[INFO] 'creating C:\\Users\\Nick's Laptop\\Desktop\\Health Analyics\\medical_image_analysis\\malaria\\testing\\Parasitized' directory\n",
      "[INFO] 'creating C:\\Users\\Nick's Laptop\\Desktop\\Health Analyics\\medical_image_analysis\\malaria\\testing\\Uninfected' directory\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "(\"training\", trainPaths, train_path),\n",
    "(\"validation\", valPaths, val_path),\n",
    "(\"testing\", testPaths, test_path)\n",
    "]\n",
    "\n",
    "# loop over the datasets\n",
    "\n",
    "for (dType, imagePaths, baseOutput) in datasets:\n",
    "\n",
    "    # show which data split we are creating\n",
    "    print(\"[INFO] building '{}' split\".format(dType))\n",
    "\n",
    "    # if the output base output directory does not exist, create it\n",
    "    if not os.path.exists(baseOutput):\n",
    "        print(\"[INFO] 'creating {}' directory\".format(baseOutput))\n",
    "        os.makedirs(baseOutput)\n",
    "\n",
    "    # loop over the input image paths\n",
    "    for inputPath in imagePaths:\n",
    "        # extract the filename of the input image along with its\n",
    "        # corresponding class label\n",
    "        filename = inputPath.split(os.path.sep)[-1]\n",
    "        label = inputPath.split(os.path.sep)[-2]\n",
    "\n",
    "        # build the path to the label directory\n",
    "        labelPath = os.path.sep.join([baseOutput, label])\n",
    "\n",
    "        # if the label output directory does not exist, create it\n",
    "        if not os.path.exists(labelPath):\n",
    "            print(\"[INFO] 'creating {}' directory\".format(labelPath))\n",
    "            os.makedirs(labelPath)\n",
    "\n",
    "        # construct the path to the destination image and then copy\n",
    "        # the image itself\n",
    "        p = os.path.sep.join([labelPath, filename])\n",
    "        shutil.copy2(inputPath, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360a993e",
   "metadata": {},
   "source": [
    "## Design your CNN using keras and use pretrained network VGG16 or VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f00b77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base = VGG16(weights = \"imagenet\",\n",
    "include_top = False)\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68932e38",
   "metadata": {},
   "source": [
    "## Use keras ImageGenerator adjust features from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12d76c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rescale=1 / 255.0,\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.05,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=0.05,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "valGen = ImageDataGenerator(rescale=1 / 255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df08743a",
   "metadata": {},
   "source": [
    "## Run processing steps on images in train/validate/test directories. Training and validation generators were shuffled. The training generator uses the more comprehensive ImageDataGenerator, while the validation and testing generators were given the copy provided in the assignment  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "562ec309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19842 images belonging to 2 classes.\n",
      "Found 2204 images belonging to 2 classes.\n",
      "Found 5512 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = datagen.flow_from_directory(\n",
    "    train_path, target_size=(64, 64), color_mode='rgb',\n",
    "    class_mode='categorical', batch_size=32, shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = valGen.flow_from_directory(\n",
    "    val_path, target_size=(64, 64), color_mode='rgb',\n",
    "    class_mode='categorical', batch_size=32, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "test_gen = valGen.flow_from_directory(\n",
    "    test_path, target_size=(64, 64), color_mode='rgb',\n",
    "    class_mode='categorical', batch_size=32, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03751ad",
   "metadata": {},
   "source": [
    "## Extract test features and labels for modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cae1d0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed size = 4000\n",
      "processed size = 8000\n",
      "processed size = 12000\n",
      "processed size = 16000\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "labels = []\n",
    "batch_size = 32\n",
    "sample_count = 19842\n",
    "i = 0\n",
    "for inputs_batch, labels_batch in train_gen:\n",
    "\n",
    "#print(labels_batch)\n",
    "    features_batch = conv_base.predict(inputs_batch)\n",
    "    features[i * batch_size: (i+1) * batch_size] = features_batch\n",
    "    labels[i * batch_size: (i+1) * batch_size] = labels_batch\n",
    "    i += 1\n",
    "    if ((i * batch_size % 1000) == 0 ):\n",
    "       print(\"processed size =\", i * batch_size)\n",
    "    if (i * batch_size >= sample_count):\n",
    "        break\n",
    "\n",
    "np.save('train_features', features)\n",
    "np.save('train_labels', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45729fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "batch_size = 32\n",
    "sample_count = 2204\n",
    "i = 0\n",
    "for inputs_batch, labels_batch in val_gen:\n",
    "\n",
    "#print(labels_batch)\n",
    "    features_batch = conv_base.predict(inputs_batch)\n",
    "    features[i * batch_size: (i+1) * batch_size] = features_batch\n",
    "    labels[i * batch_size: (i+1) * batch_size] = labels_batch\n",
    "    i += 1\n",
    "    if ((i * batch_size % 1000) == 0 ):\n",
    "       print(\"processed size =\", i * batch_size)\n",
    "    if (i * batch_size >= sample_count):\n",
    "        break\n",
    "\n",
    "np.save('val_features', features)\n",
    "np.save('val_labels', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa76ec3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed size = 4000\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "labels = []\n",
    "batch_size = 32\n",
    "sample_count = 5512\n",
    "i = 0\n",
    "for inputs_batch, labels_batch in test_gen:\n",
    "\n",
    "#print(labels_batch)\n",
    "    features_batch = conv_base.predict(inputs_batch)\n",
    "    features[i * batch_size: (i+1) * batch_size] = features_batch\n",
    "    labels[i * batch_size: (i+1) * batch_size] = labels_batch\n",
    "    i += 1\n",
    "    if ((i * batch_size % 1000) == 0 ):\n",
    "       print(\"processed size =\", i * batch_size)\n",
    "    if (i * batch_size >= sample_count):\n",
    "        break\n",
    "\n",
    "np.save('test_features', features)\n",
    "np.save('test_labels', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9467da8a",
   "metadata": {},
   "source": [
    "## Save features and labels for later use, check length to ensure accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59abc8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.load('train_features.npy')\n",
    "train_labels = np.load('train_labels.npy')\n",
    "val_features = np.load('val_features.npy')\n",
    "val_labels = np.load('val_labels.npy')\n",
    "test_features = np.load('test_features.npy')\n",
    "test_labels = np.load('test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7249afea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features:  (19842, 2, 2, 512)\n",
      "train_labels:  (19842, 2)\n",
      "val_features:  (2204, 2, 2, 512)\n",
      "val_labels:  (2204, 2)\n",
      "test_features:  (5512, 2, 2, 512)\n",
      "test_labels:  (5512, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_features: \", train_features.shape)\n",
    "print(\"train_labels: \", train_labels.shape)\n",
    "print(\"val_features: \", val_features.shape)\n",
    "print(\"val_labels: \", val_labels.shape)\n",
    "print(\"test_features: \", test_features.shape)\n",
    "print(\"test_labels: \", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00cd802",
   "metadata": {},
   "source": [
    "## Model Tuning: other keras layers were tried (e.g., dropout, BatchNormalization, GlorotNormal) but these parameters seemed to yield the optimal results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5d8fc6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish model, including features you would like to test \n",
    "model = tf.keras.models.Sequential([\n",
    "     tf.keras.layers.Conv2D(8,kernel_size=(1,1), activation='sigmoid',input_shape=(2, 2, 512)),\n",
    "     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "     tf.keras.layers.Flatten(),\n",
    "     tf.keras.layers.Dense(16, activation='relu'),\n",
    "     tf.keras.layers.Dense(1, activation='sigmoid', input_shape=(2, 2, 512))\n",
    "     ])\n",
    "\n",
    "# Compile the model, indicating loss type, optimizer, and metrics of interest \n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=Adam(learning_rate=1e-3),metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ff3f3",
   "metadata": {},
   "source": [
    "## fit_generator tuning: 15 epochs appears to consistently produce the highest accuracy and lowest test loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "888fb8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 0.3730 - binary_accuracy: 0.8525 - val_loss: 0.2297 - val_binary_accuracy: 0.9170\n",
      "Epoch 2/15\n",
      "621/621 [==============================] - 1s 996us/step - loss: 0.2215 - binary_accuracy: 0.9165 - val_loss: 0.2077 - val_binary_accuracy: 0.9201\n",
      "Epoch 3/15\n",
      "621/621 [==============================] - 1s 974us/step - loss: 0.2029 - binary_accuracy: 0.9248 - val_loss: 0.1928 - val_binary_accuracy: 0.9297\n",
      "Epoch 4/15\n",
      "621/621 [==============================] - 1s 980us/step - loss: 0.1932 - binary_accuracy: 0.9299 - val_loss: 0.1814 - val_binary_accuracy: 0.9383\n",
      "Epoch 5/15\n",
      "621/621 [==============================] - 1s 986us/step - loss: 0.1838 - binary_accuracy: 0.9331 - val_loss: 0.1742 - val_binary_accuracy: 0.9387\n",
      "Epoch 6/15\n",
      "621/621 [==============================] - 1s 981us/step - loss: 0.1776 - binary_accuracy: 0.9345 - val_loss: 0.1702 - val_binary_accuracy: 0.9442\n",
      "Epoch 7/15\n",
      "621/621 [==============================] - 1s 978us/step - loss: 0.1719 - binary_accuracy: 0.9368 - val_loss: 0.1655 - val_binary_accuracy: 0.9419\n",
      "Epoch 8/15\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 0.1688 - binary_accuracy: 0.9370 - val_loss: 0.1686 - val_binary_accuracy: 0.9451\n",
      "Epoch 9/15\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 0.1664 - binary_accuracy: 0.9385 - val_loss: 0.1642 - val_binary_accuracy: 0.9442\n",
      "Epoch 10/15\n",
      "621/621 [==============================] - 1s 993us/step - loss: 0.1621 - binary_accuracy: 0.9395 - val_loss: 0.1606 - val_binary_accuracy: 0.9442\n",
      "Epoch 11/15\n",
      "621/621 [==============================] - 1s 979us/step - loss: 0.1586 - binary_accuracy: 0.9397 - val_loss: 0.1741 - val_binary_accuracy: 0.9383\n",
      "Epoch 12/15\n",
      "621/621 [==============================] - 1s 986us/step - loss: 0.1561 - binary_accuracy: 0.9413 - val_loss: 0.1593 - val_binary_accuracy: 0.9428\n",
      "Epoch 13/15\n",
      "621/621 [==============================] - 1s 978us/step - loss: 0.1550 - binary_accuracy: 0.9408 - val_loss: 0.1647 - val_binary_accuracy: 0.9410\n",
      "Epoch 14/15\n",
      "621/621 [==============================] - 1s 989us/step - loss: 0.1500 - binary_accuracy: 0.9436 - val_loss: 0.1590 - val_binary_accuracy: 0.9442\n",
      "Epoch 15/15\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 0.1505 - binary_accuracy: 0.9434 - val_loss: 0.1584 - val_binary_accuracy: 0.9437\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_features,train_labels[:,0], batch_size=32, \n",
    "                    epochs=15, validation_data=(val_features, val_labels[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ffe9c",
   "metadata": {},
   "source": [
    "## Check test accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "99379e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 0s 595us/step - loss: 0.1532 - binary_accuracy: 0.9434\n",
      "Test loss: 0.1531982272863388\n",
      "Test accuracy: 0.9433962106704712\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_features,test_labels[:,0])\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
