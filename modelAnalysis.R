# Create variable dataPath equal to path to your local folder where you saved the data file Week5_Test_Sample.csv
dataPath <- "C:/Users/Nick's Laptop/Desktop/Statistical Analysis"

# Initial data file with training sample 
train_dat <- read.table(paste(dataPath,'Week6_Test_Sample_Train.csv',sep = '/'), header=TRUE)

# Training data with columns matching column structure in workshop
LinearModel.Training<-train_dat[,c(2,1,3)]

main_dat <- read.table(paste(dataPath,'Week6_Test_Sample_Test.csv',sep = '/'), header=TRUE)

# Same column adjustment for primary data 
LinearModel<-main_dat[,c(2,1)]


nSample.Training<-length(LinearModel.Training[,1])
head(LinearModel.Training)

# Plot the training sample
plot(LinearModel.Training[,1],LinearModel.Training[,2], type="p",pch=19)

# Define training samples generated by model 1 and model 2
LinearModel.Training.1<-cbind(LinearModel.Training[,1],rep(NA,nSample.Training))
LinearModel.Training.2<-cbind(LinearModel.Training[,1],rep(NA,nSample.Training))
LinearModel.Training.1[LinearModel.Training[,3]*(1:nSample.Training),2]<-
  LinearModel.Training[LinearModel.Training[,3]*(1:nSample.Training),2]
LinearModel.Training.2[(1-LinearModel.Training[,3])*(1:nSample.Training),2]<-
  LinearModel.Training[(1-LinearModel.Training[,3])*(1:nSample.Training),2]

head(cbind(LinearModel.Training,
           Trainig1=LinearModel.Training.1[,2],
           Training2=LinearModel.Training.2[,2]))

# Plot the subsamples
matplot(LinearModel.Training[,1],cbind(LinearModel.Training.1[,2],LinearModel.Training.2[,2]),
        pch=16,col=c("green","blue"),ylab="Subsamples of the training sample")


EstimatedLinearModel.Training <- lm(Output ~ Input,data=LinearModel.Training)

summary(EstimatedLinearModel.Training)$coefficients

# R squared of .95, meaning the data is highly correlated (goes from -1 to 1)
summary(EstimatedLinearModel.Training)$r.squared

# Sigma is amount of noise. As it is reduced fitted/actual values (y and y hat) become closer 
summary(EstimatedLinearModel.Training)$sigma

# Residuals seem to be relatively evenly distributed. No major areas of clustering
EstimatedResiduals.Training<-EstimatedLinearModel.Training$residuals
plot(LinearModel.Training[,1],EstimatedResiduals.Training)


# Using the third column of the training sample separate and plot the residuals for observations from different models

# Define residuals corresponding to different models 
EstimatedResiduals.Training.1<-EstimatedResiduals.Training
EstimatedResiduals.Training.2<-EstimatedResiduals.Training
EstimatedResiduals.Training.1[(LinearModel.Training[,3]==0)*(1:nSample.Training)]<-NA
EstimatedResiduals.Training.2[(LinearModel.Training[,3]==1)*(1:nSample.Training)]<-NA
# Print the first ten columns to check the separation 
head(cbind(AllResiduals=EstimatedResiduals.Training,
           Training1Residuals=EstimatedResiduals.Training.1,
           Training2Residuals=EstimatedResiduals.Training.2,
           TrainingClass=LinearModel.Training[,3]))

# Plot the residuals corresponding to different models
matplot(LinearModel.Training[,1],cbind(EstimatedResiduals.Training.1,
                                       EstimatedResiduals.Training.2),
        pch=16,col=c("green","blue"),ylab="Separated parts of the training sample")


# Create the data frame for logistic regression
Logistic.Model.Data<-data.frame(Logistic.Output=LinearModel.Training[,3],
                                Logistic.Input=EstimatedResiduals.Training)
LinearModel.Training.Logistic<-glm(Logistic.Output~Logistic.Input,data=Logistic.Model.Data,
                                   family=binomial(link=logit))
summary(LinearModel.Training.Logistic)


# Define and plot probability of selecting an observation from the first model using predict function with type="response" argument. Plot the predicted probabilities
Predicted.Probabilities.Training<-predict(LinearModel.Training.Logistic,type="response")
plot(LinearModel.Training[,1],Predicted.Probabilities.Training)

# Classify the training sample using the estimated unscrambling sequence

# Create the unscrambling sequence for the training sample
Unscrambling.Sequence.Training.Logistic<-
  (predict(LinearModel.Training.Logistic,type="response")>.5)*1
# Create classified residuals
ClassifiedResiduals.Training.1<-EstimatedResiduals.Training
ClassifiedResiduals.Training.2<-EstimatedResiduals.Training
ClassifiedResiduals.Training.1[(Unscrambling.Sequence.Training.Logistic==0)*
                                 (1:nSample.Training)]<-NA
ClassifiedResiduals.Training.2[(Unscrambling.Sequence.Training.Logistic==1)*
                                 (1:nSample.Training)]<-NA
head(cbind(AllTraining=EstimatedResiduals.Training,
           Training1=ClassifiedResiduals.Training.1,
           Training2=ClassifiedResiduals.Training.2))


# Plot both classes of the residuals
matplot(LinearModel.Training[,1],cbind(ClassifiedResiduals.Training.1,
                                       ClassifiedResiduals.Training.2),
        pch=16,col=c("green","blue"),ylab="Classified residuals, X-axis at 0")
axis(1,pos=0)


Classification.Rule.Logistic<- # X= -B0/B1 (When greater than 0, 1, when less than 0, 0)
  test<- ((mean(LinearModel.Training$Output)*-1)/(EstimatedLinearModel.Training$fitted.values-mean(LinearModel.Training$Output))) ### NEED TO FIGURE THIS OUT 

# 1.3. Separate subsamples in the main sample using the classifier trained on the training sample
# Read the main sample.
nSample<-length(LinearModel[,1])
head(LinearModel)

# Generate Linear model for test data 
EstimatedLinearModel<-lm(LinearModel[,2]~LinearModel[,1])

# Check coefficients 
EstimatedLinearModel$coefficients

# Extract and plot residuals from test model 
EstimatedResiduals<-EstimatedLinearModel$residuals
plot(LinearModel[,1],EstimatedResiduals)

# Figure out how this is working
Unscrambling.Sequence.Logistic<-(predict(LinearModel.Training.Logistic,                                         newdata=data.frame(Logistic.Output=EstimatedResiduals,                              Logistic.Input=EstimatedResiduals),
                                         type="response")>.5)*1

res <- list(Unscrambling.Sequence.Logistic =  Unscrambling.Sequence.Logistic)

write.table(res, file = paste(dataPath,'result.csv',sep = '/'), row.names = F)
